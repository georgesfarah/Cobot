{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "DeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.3 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "5c0372ed38b372118c24adb00d45654d76c8d10261533c5724e3f5fc1d75489a"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "import tensorflow as tf\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.feature_selection import SelectKBest, chi2\r\n",
        "import os"
      ],
      "outputs": [],
      "metadata": {
        "id": "PMTc4rFyjh5v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "le = preprocessing.LabelEncoder()\r\n",
        "\r\n",
        "accuracy1_data=pd.read_csv(\"../Datasets/accuracy2.csv\")\r\n",
        "\r\n",
        "accuracy1_data=accuracy1_data.fillna(value=-150)\r\n",
        "\r\n",
        "# Create feature and target arrays\r\n",
        "y_tmp=accuracy1_data['location']\r\n",
        "y=le.fit_transform(y_tmp)\r\n",
        "X=accuracy1_data\r\n",
        "X=X.drop(['location'], axis = 1)\r\n",
        "X=(X-X.mean())/X.std()\r\n",
        "X+=3\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0,stratify=y)\r\n",
        "\r\n",
        "\r\n",
        "X_train.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    00:41:D2:C1:C1:32  88:F0:77:FD:F9:00  00:41:D2:C1:C1:30  \\\n",
              "73           1.634256           2.707817            1.94545   \n",
              "77           1.634256           2.707817            1.94545   \n",
              "66           3.675290           2.707817            3.88397   \n",
              "8            1.634256           2.707817            1.94545   \n",
              "32           1.634256           2.707817            1.94545   \n",
              "\n",
              "    00:41:D2:C1:C1:39  88:F0:77:FD:F9:09  C2:2B:F9:8D:63:ED  \\\n",
              "73           1.845976           2.707875           5.296872   \n",
              "77           1.845976           2.707875           5.591601   \n",
              "66           3.820358           2.707875           2.054860   \n",
              "8            1.845976           2.707875           2.526425   \n",
              "32           1.845976           2.707875           2.231697   \n",
              "\n",
              "    88:F0:77:FD:AB:20  00:DA:55:72:48:82  00:DA:55:51:CC:B9  \\\n",
              "73           2.813223           2.685845           2.708393   \n",
              "77           2.813223           2.685845           2.708393   \n",
              "66           2.813223           2.685845           2.708393   \n",
              "8            2.813223           2.685845           2.708393   \n",
              "32           2.813223           2.685845           2.708393   \n",
              "\n",
              "    00:DA:55:72:48:89  ...  88:F0:77:FD:CD:12  88:F0:77:FD:E3:00  \\\n",
              "73            2.81337  ...            2.84837             2.8934   \n",
              "77            2.81337  ...            2.84837             2.8934   \n",
              "66            2.81337  ...            2.84837             2.8934   \n",
              "8             2.81337  ...            2.84837             2.8934   \n",
              "32            2.81337  ...            2.84837             2.8934   \n",
              "\n",
              "    88:F0:77:FD:A8:90  00:DA:55:51:CC:B0  00:DA:55:72:48:80  \\\n",
              "73             2.8934             2.8934             2.8934   \n",
              "77             2.8934             2.8934             2.8934   \n",
              "66             2.8934             2.8934             2.8934   \n",
              "8              2.8934             2.8934             2.8934   \n",
              "32             2.8934             2.8934             2.8934   \n",
              "\n",
              "    78:72:5D:8E:C4:C2  78:72:5D:8E:C4:C0  78:72:5D:8E:C4:C9  \\\n",
              "73             2.8934             2.8934             2.8934   \n",
              "77             2.8934             2.8934             2.8934   \n",
              "66             2.8934             2.8934             2.8934   \n",
              "8              2.8934             2.8934             2.8934   \n",
              "32             2.8934             2.8934             2.8934   \n",
              "\n",
              "    00:DA:55:72:43:89  88:F0:77:FD:FF:59  \n",
              "73             2.8934             2.8934  \n",
              "77             2.8934             2.8934  \n",
              "66             2.8934             2.8934  \n",
              "8              2.8934             2.8934  \n",
              "32             2.8934             2.8934  \n",
              "\n",
              "[5 rows x 78 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00:41:D2:C1:C1:32</th>\n",
              "      <th>88:F0:77:FD:F9:00</th>\n",
              "      <th>00:41:D2:C1:C1:30</th>\n",
              "      <th>00:41:D2:C1:C1:39</th>\n",
              "      <th>88:F0:77:FD:F9:09</th>\n",
              "      <th>C2:2B:F9:8D:63:ED</th>\n",
              "      <th>88:F0:77:FD:AB:20</th>\n",
              "      <th>00:DA:55:72:48:82</th>\n",
              "      <th>00:DA:55:51:CC:B9</th>\n",
              "      <th>00:DA:55:72:48:89</th>\n",
              "      <th>...</th>\n",
              "      <th>88:F0:77:FD:CD:12</th>\n",
              "      <th>88:F0:77:FD:E3:00</th>\n",
              "      <th>88:F0:77:FD:A8:90</th>\n",
              "      <th>00:DA:55:51:CC:B0</th>\n",
              "      <th>00:DA:55:72:48:80</th>\n",
              "      <th>78:72:5D:8E:C4:C2</th>\n",
              "      <th>78:72:5D:8E:C4:C0</th>\n",
              "      <th>78:72:5D:8E:C4:C9</th>\n",
              "      <th>00:DA:55:72:43:89</th>\n",
              "      <th>88:F0:77:FD:FF:59</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>1.634256</td>\n",
              "      <td>2.707817</td>\n",
              "      <td>1.94545</td>\n",
              "      <td>1.845976</td>\n",
              "      <td>2.707875</td>\n",
              "      <td>5.296872</td>\n",
              "      <td>2.813223</td>\n",
              "      <td>2.685845</td>\n",
              "      <td>2.708393</td>\n",
              "      <td>2.81337</td>\n",
              "      <td>...</td>\n",
              "      <td>2.84837</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>1.634256</td>\n",
              "      <td>2.707817</td>\n",
              "      <td>1.94545</td>\n",
              "      <td>1.845976</td>\n",
              "      <td>2.707875</td>\n",
              "      <td>5.591601</td>\n",
              "      <td>2.813223</td>\n",
              "      <td>2.685845</td>\n",
              "      <td>2.708393</td>\n",
              "      <td>2.81337</td>\n",
              "      <td>...</td>\n",
              "      <td>2.84837</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>3.675290</td>\n",
              "      <td>2.707817</td>\n",
              "      <td>3.88397</td>\n",
              "      <td>3.820358</td>\n",
              "      <td>2.707875</td>\n",
              "      <td>2.054860</td>\n",
              "      <td>2.813223</td>\n",
              "      <td>2.685845</td>\n",
              "      <td>2.708393</td>\n",
              "      <td>2.81337</td>\n",
              "      <td>...</td>\n",
              "      <td>2.84837</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.634256</td>\n",
              "      <td>2.707817</td>\n",
              "      <td>1.94545</td>\n",
              "      <td>1.845976</td>\n",
              "      <td>2.707875</td>\n",
              "      <td>2.526425</td>\n",
              "      <td>2.813223</td>\n",
              "      <td>2.685845</td>\n",
              "      <td>2.708393</td>\n",
              "      <td>2.81337</td>\n",
              "      <td>...</td>\n",
              "      <td>2.84837</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1.634256</td>\n",
              "      <td>2.707817</td>\n",
              "      <td>1.94545</td>\n",
              "      <td>1.845976</td>\n",
              "      <td>2.707875</td>\n",
              "      <td>2.231697</td>\n",
              "      <td>2.813223</td>\n",
              "      <td>2.685845</td>\n",
              "      <td>2.708393</td>\n",
              "      <td>2.81337</td>\n",
              "      <td>...</td>\n",
              "      <td>2.84837</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "      <td>2.8934</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 78 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "metadata": {
        "id": "vKLzQCs2kDdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c35dc0-1e23-4c8d-c2fb-a2bedd987829"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "bestfeatures = SelectKBest(score_func=chi2, k=10)\r\n",
        "fit = bestfeatures.fit(X_train,y_train)\r\n",
        "dfscores = pd.DataFrame(fit.scores_)\r\n",
        "dfcolumns = pd.DataFrame(X_train.columns)\r\n",
        "\r\n",
        "#concat two dataframes for better visualization\r\n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\r\n",
        "featureScores.columns = ['Specs','Score'] #naming the dataframe columns"
      ],
      "outputs": [],
      "metadata": {
        "id": "09EnstNwk2gX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "my_features=list(featureScores.nlargest(20,'Score').Specs)\r\n",
        "\r\n",
        "X_train=X_train[my_features]\r\n",
        "X_test=X_test[my_features]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Dense(len(X_train.columns)),\r\n",
        "                                \r\n",
        "                                    tf.keras.layers.Dense(15, activation='tanh'),\r\n",
        "\r\n",
        "                                    tf.keras.layers.Dense(12),\r\n",
        "\r\n",
        "                                    tf.keras.layers.Dense(10, activation='softmax')])"
      ],
      "outputs": [],
      "metadata": {
        "id": "_XGNgejUl-W6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "2QD_liI2mS_J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "early_stop_callback= tf.keras.callbacks.EarlyStopping(\r\n",
        "    monitor='accuracy', min_delta=0, patience=20, verbose=1,\r\n",
        "    mode='max', baseline=None, restore_best_weights=True\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "yU8nIGqZ7bsv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "os.makedirs('tmp', exist_ok = True)\r\n",
        "\r\n",
        "checkpoint_filepath = 'tmp/checkpoint-{epoch:03d}-{accuracy:.4f}.hdf5'\r\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath=checkpoint_filepath,\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='accuracy',\r\n",
        "    mode='max',\r\n",
        "    save_best_only=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "PSR_kx865R9z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.fit(X_train,y_train,epochs=250,batch_size=28, callbacks=[early_stop_callback,checkpoint_callback])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.4786 - accuracy: 0.1667\n",
            "Epoch 2/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.4140 - accuracy: 0.1818\n",
            "Epoch 3/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 2.3567 - accuracy: 0.2121\n",
            "Epoch 4/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.3139 - accuracy: 0.1970\n",
            "Epoch 5/250\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 2.2809 - accuracy: 0.1818\n",
            "Epoch 6/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 2.2554 - accuracy: 0.1515\n",
            "Epoch 7/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 2.2304 - accuracy: 0.1818\n",
            "Epoch 8/250\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 2.2144 - accuracy: 0.1818\n",
            "Epoch 9/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 2.1971 - accuracy: 0.1667\n",
            "Epoch 10/250\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 2.1836 - accuracy: 0.1667\n",
            "Epoch 11/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2.1677 - accuracy: 0.1515\n",
            "Epoch 12/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.1539 - accuracy: 0.1515\n",
            "Epoch 13/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 2.1379 - accuracy: 0.1818\n",
            "Epoch 14/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 2.1212 - accuracy: 0.1970\n",
            "Epoch 15/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 2.1027 - accuracy: 0.1970\n",
            "Epoch 16/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 2.0893 - accuracy: 0.2273\n",
            "Epoch 17/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 2.0729 - accuracy: 0.1970\n",
            "Epoch 18/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.0556 - accuracy: 0.1970\n",
            "Epoch 19/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2.0376 - accuracy: 0.1970\n",
            "Epoch 20/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 2.0179 - accuracy: 0.2576\n",
            "Epoch 21/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 2.0022 - accuracy: 0.2576\n",
            "Epoch 22/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.9865 - accuracy: 0.2424\n",
            "Epoch 23/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.9709 - accuracy: 0.2424\n",
            "Epoch 24/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.9528 - accuracy: 0.2273\n",
            "Epoch 25/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.9316 - accuracy: 0.2424\n",
            "Epoch 26/250\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.9111 - accuracy: 0.2727\n",
            "Epoch 27/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.8929 - accuracy: 0.3030\n",
            "Epoch 28/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.8749 - accuracy: 0.3030\n",
            "Epoch 29/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.8625 - accuracy: 0.3030\n",
            "Epoch 30/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.8454 - accuracy: 0.3030\n",
            "Epoch 31/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.8300 - accuracy: 0.3030\n",
            "Epoch 32/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.8116 - accuracy: 0.2879\n",
            "Epoch 33/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.7962 - accuracy: 0.3182\n",
            "Epoch 34/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.7809 - accuracy: 0.3485\n",
            "Epoch 35/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.7659 - accuracy: 0.3485\n",
            "Epoch 36/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.7532 - accuracy: 0.3485\n",
            "Epoch 37/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.7387 - accuracy: 0.3636\n",
            "Epoch 38/250\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 1.7235 - accuracy: 0.3636\n",
            "Epoch 39/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.7113 - accuracy: 0.3485\n",
            "Epoch 40/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.6996 - accuracy: 0.3485\n",
            "Epoch 41/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.6872 - accuracy: 0.3485\n",
            "Epoch 42/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.6737 - accuracy: 0.3485\n",
            "Epoch 43/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.6646 - accuracy: 0.3333\n",
            "Epoch 44/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.6520 - accuracy: 0.3788\n",
            "Epoch 45/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.6371 - accuracy: 0.3788\n",
            "Epoch 46/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.6258 - accuracy: 0.3788\n",
            "Epoch 47/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.6157 - accuracy: 0.3939\n",
            "Epoch 48/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.6033 - accuracy: 0.3939\n",
            "Epoch 49/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.5926 - accuracy: 0.3939\n",
            "Epoch 50/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.5834 - accuracy: 0.4394\n",
            "Epoch 51/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.5723 - accuracy: 0.4848\n",
            "Epoch 52/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.5611 - accuracy: 0.4394\n",
            "Epoch 53/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.5513 - accuracy: 0.4394\n",
            "Epoch 54/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.5428 - accuracy: 0.4697\n",
            "Epoch 55/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.5315 - accuracy: 0.4848\n",
            "Epoch 56/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.5216 - accuracy: 0.4848\n",
            "Epoch 57/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.5126 - accuracy: 0.4848\n",
            "Epoch 58/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.5035 - accuracy: 0.4848\n",
            "Epoch 59/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.4942 - accuracy: 0.4848\n",
            "Epoch 60/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.4848 - accuracy: 0.5000\n",
            "Epoch 61/250\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.4759 - accuracy: 0.5000\n",
            "Epoch 62/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.4677 - accuracy: 0.4545\n",
            "Epoch 63/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.4589 - accuracy: 0.4394\n",
            "Epoch 64/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.4502 - accuracy: 0.4697\n",
            "Epoch 65/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.4406 - accuracy: 0.4697\n",
            "Epoch 66/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.4348 - accuracy: 0.4697\n",
            "Epoch 67/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.4244 - accuracy: 0.5000\n",
            "Epoch 68/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.4161 - accuracy: 0.5000\n",
            "Epoch 69/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.4085 - accuracy: 0.5000\n",
            "Epoch 70/250\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 1.3998 - accuracy: 0.5000\n",
            "Epoch 71/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.3905 - accuracy: 0.5000\n",
            "Epoch 72/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.3841 - accuracy: 0.5000\n",
            "Epoch 73/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.3758 - accuracy: 0.5000\n",
            "Epoch 74/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.3677 - accuracy: 0.4848\n",
            "Epoch 75/250\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.3629 - accuracy: 0.4848\n",
            "Epoch 76/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.3481 - accuracy: 0.4848\n",
            "Epoch 77/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.3462 - accuracy: 0.4697\n",
            "Epoch 78/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.3351 - accuracy: 0.5152\n",
            "Epoch 79/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.3250 - accuracy: 0.5152\n",
            "Epoch 80/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.3155 - accuracy: 0.5455\n",
            "Epoch 81/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.3072 - accuracy: 0.5303\n",
            "Epoch 82/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.3031 - accuracy: 0.5455\n",
            "Epoch 83/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.2942 - accuracy: 0.4848\n",
            "Epoch 84/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.2843 - accuracy: 0.5152\n",
            "Epoch 85/250\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.2751 - accuracy: 0.5455\n",
            "Epoch 86/250\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 1.2652 - accuracy: 0.5606\n",
            "Epoch 87/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.2601 - accuracy: 0.5303\n",
            "Epoch 88/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.2598 - accuracy: 0.5152\n",
            "Epoch 89/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.2509 - accuracy: 0.5152\n",
            "Epoch 90/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.2414 - accuracy: 0.5606\n",
            "Epoch 91/250\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.2330 - accuracy: 0.5606\n",
            "Epoch 92/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.2275 - accuracy: 0.5758\n",
            "Epoch 93/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.2212 - accuracy: 0.5909\n",
            "Epoch 94/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.2150 - accuracy: 0.5909\n",
            "Epoch 95/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.2039 - accuracy: 0.5758\n",
            "Epoch 96/250\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.1969 - accuracy: 0.5455\n",
            "Epoch 97/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.1906 - accuracy: 0.5303\n",
            "Epoch 98/250\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.1818 - accuracy: 0.5455\n",
            "Epoch 99/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.1771 - accuracy: 0.5152\n",
            "Epoch 100/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.1714 - accuracy: 0.5455\n",
            "Epoch 101/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.1726 - accuracy: 0.5606\n",
            "Epoch 102/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.1650 - accuracy: 0.5455\n",
            "Epoch 103/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.1563 - accuracy: 0.5152\n",
            "Epoch 104/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.1466 - accuracy: 0.5606\n",
            "Epoch 105/250\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 1.1423 - accuracy: 0.5758\n",
            "Epoch 106/250\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.1360 - accuracy: 0.5758\n",
            "Epoch 107/250\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.1304 - accuracy: 0.5758\n",
            "Epoch 108/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.1255 - accuracy: 0.5758\n",
            "Epoch 109/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.1212 - accuracy: 0.5606\n",
            "Epoch 110/250\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 1.1108 - accuracy: 0.5758\n",
            "Epoch 111/250\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.1110 - accuracy: 0.5758\n",
            "Epoch 112/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.1025 - accuracy: 0.5909\n",
            "Epoch 113/250\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.0982 - accuracy: 0.5455\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00113: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2b5036d090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEHUOF9Fmie9",
        "outputId": "338954cf-8d96-4feb-cfbc-4801de5d114e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 107ms/step - loss: 1.6456 - accuracy: 0.3182\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.645643949508667, 0.3181818127632141]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b-j9mNsmsb4",
        "outputId": "e9047ff2-780e-49fe-d1e3-9047c9c0201e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#model.save('accuracy2-45.hdf5')"
      ],
      "outputs": [],
      "metadata": {
        "id": "Iw1TNTGbm2gs"
      }
    }
  ]
}